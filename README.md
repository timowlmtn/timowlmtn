# **Tim Burns**

**Email:** [timburnsowlmtn@gmail.com](mailto:timburnsowlmtn@gmail.com)  
**Phone:** (401) 954-1620  
**Location:** Greater Boston Area  
**LinkedIn:** [linkedin.com/in/tim-burns-5aa6141](https://linkedin.com/in/tim-burns-5aa6141)

---

## **Professional Experience**

### **Evolve Vacation Rental**  
**Principal Data Architect**  
*May 2023 – March 2025 | Remote*

- Transformed a Salesforce-based pricing system by migrating geospatial price modifiers to a scalable REST API stack (Leaflet, GraphQL, Gunicorn, Snowflake), resulting in enhanced pricing precision and operational agility.

- Engineered a high-performance Gunicorn-served microservice that dynamically adjusted regional pricing through real-time geocode queries, optimizing market-specific strategies and driving faster decision-making.

- Implemented real-time pricing updates by streaming high-volume data into Postgres via AWS SQS, significantly improving market responsiveness and pricing accuracy.

- Led a comprehensive bakeoff to evaluate multiple third-party pricing vendors against key performance criteria such as revenue impact and booking density, ultimately selecting a robust solution to replace the legacy in-house system.

- Modernized a legacy Heroku pricing system by transitioning to a dbt-driven architecture deployed through Terraform and ArgoCD, establishing a continuously delivered pipeline that reduced operational costs and enhanced deployment reliability.

**Key Achievements:**
- Boosted revenue per booked night by leveraging targeted pricing architecture and advanced demand forecasting, leading to measurable financial improvements.

- Reduced operational expenses by migrating an expensive Salesforce pricing pipeline to internal open source tools (dbt, GraphQL), streamlining processes and cutting costs.

- Elevated code quality and cross-team collaboration by implementing automated quality gates—merge checklists, test hooks, and format validation—within the CI/CD pipeline.

**Tech Stack**
- **Languages & Frameworks**: Python, Typescript, Node.js, SQL

- **Data Platforms**: Snowflake, Salesforce

- **Cloud & DevOps**: AWS (EKS, SQS)

- **Data Engineering & Analytics**: dbt, Spark, Jupyter, Pytorch, Metabase, Tableau

---

### **Abacus Insights**  
**Senior Software Engineer**  
*October 2021 – April 2023 | Boston, MA*

- Developed a Databricks-Snowflake in using Delta Lake marts to offload all data processing to Databricks, utilizing Snowflake exclusively for data sharing—resulting in over $2,000 monthly savings in CPU usage costs.

- Migrated and optimized complex healthcare data systems from legacy Oracle infrastructure to a streamlined Snowflake environment, significantly reducing operational costs and enabling near-real-time claim integration.

- Implemented clinical analytics dashboards integrating claims, lab, and patient data, delivering actionable insights and proactive alerts for diabetes and obesity management.

- Delivered substantial Snowflake cost reductions by simplifying complex SQL code and ETL processes, improving query performance and operational efficiency.

- Transformed Salesforce-based pricing architecture into scalable REST API services, significantly improving market responsiveness and revenue per booked night.

- Designed and executed rigorous vendor evaluations (bakeoffs) based on revenue impact and operational efficiency, effectively replacing legacy pricing systems with superior solutions.

**Tech Stack**
- **Languages & Frameworks**: Python, Java, SQL

- **Data Platforms**: Snowflake, Databricks, Oracle

- **Cloud & DevOps**: AWS (EMR, Glue, Lambda, SQS, Terraform)

- **Data Engineering & Analytics**: dbt, Medallion architecture (Bronze, Silver, Gold), Delta Lake

---

### **Kraft Analytics Group**  
**Data Architect**  
*July 2019 – October 2021 | Foxboro, MA*

- Designed and implemented a continuous deployment pipeline on AWS leveraging API Gateway, Lambda, and Redis to deliver scalable, near-real-time transactional summaries from Snowflake analytics—achieving microsecond-level responsiveness and enabling real-time sales insights for ticketing agents.

- Built a comprehensive demographic analytics Snowflake Data Mart integrating Acxiom customer survey data and rooftop-level demographic insights to enrich sales lead dashboards, significantly improving targeting accuracy and ticket sales performance.

- Integrated SnapLogic pipelines into Bitbucket CI/CD, transforming deployments from multi-hour manual processes to automated, one-click operations completed within minutes—dramatically enhancing engineering productivity and accelerating release cycles.

**Tech Stack**
- **Languages & Frameworks**: Python, Java, SQL

- **Data Platforms**: Snowflake

- **Cloud & DevOps**: AWS (API Gateway, Lambda, Redis)

- **Data Engineering & Analytics**: SnapLogic, Tableau

---

### **Virgin Pulse**  
**Architect Lead**  
*March 2018 – July 2019 | Providence, RI*

- Transitioned standard rewards reporting from Birst Analytics to a custom-built solution leveraging Airflow, Python, and Redshift, reducing licensing costs by $50K annually and enabling flexible, customizable analytics based on core rewards data.

- Developed a Python-based SQL templating and scheduling app, enabling data analysts to rapidly create and deliver customizable reports (DOC, PDF, CSV) and analytical data marts—reducing report turnaround time from weeks to hours and significantly improving responsiveness to customer needs.

- Migrated legacy on-premises SQL Server data architecture to a scalable AWS cloud platform leveraging Redshift and S3, significantly improving data availability, scalability, and reliability while reducing infrastructure overhead.

- Implemented automated generation of slowly changing dimensions and integrated dynamic data dictionaries for Tableau and DOMO, enabling high-quality self-service reporting for business stakeholders and significantly reducing reporting analyst workload.

**Tech Stack**
- **Languages & Frameworks**: Python, SQL

- **Data Platforms**: Redshift, SQL Server

- **Cloud & DevOps**: AWS (Redshift)

- **Data Engineering & Analytics**: Tableau, DOMO, Birst

---

### **Retail Solutions Inc.**  
**Full Stack Software Engineer Lead / Manager**  
*July 2002 – April 2018 | Cranston, RI*

- Designed and built a multi-timezone data tracking system to monitor receipt, processing, and quality of retail sales data, orchestrating data flow from Oracle databases into multiple MS Analytical Services instances—enabling proactive identification and resolution of critical issues such as out-of-stocks, ghost inventory, and promotional effectiveness.
 
- Integrated documentation and reporting features into a unified Microsoft stack (C#, SharePoint, SQL Server), enabling streamlined data access and providing embedded, step-by-step analytical guidance for rapid resolution of complex supply-chain issues.

- Developed a web-based reporting application using Java, Spring, and Oracle, enabling intuitive master-data editing, streamlined management of store, product, and supply-chain information, and configurable alerts—significantly enhancing data accuracy and operational efficiency.



**Tech Stack**
- **Languages & Frameworks**: Java, C#, SQL

- **Data Platforms**: Oracle, SQL Server, Sharepoint

- **Data Engineering & Analytics**: Tableau, MS Analytical Services

---

## **Certifications**

- **AWS Certified Solutions Architect – Professional** (2021)  
- **Certified Scrum Master** – Scrum Alliance (2017)

**AI/ML Specializations:**

- *Machine Learning Data Lifecycle in Production* (2023)  
- *Machine Learning in Production* (2023)  
- *Neural Networks and Deep Learning* (2024)  
- *Improving Deep Neural Networks: Hyperparameter Tuning, Regularization, and Optimization* (2024)

---

## **Publications**

- **"Securing the Snowflake Integration on AWS"** – *Snowflake, Jan 2023*  
- **"Three Literacy Tests for Hiring Data Engineers"** – *Better Programming, Apr 2022*  
- **"Integrating Snowflake with Glue"** – *Towards Data Science, Apr 2021*  
  [Link](https://medium.com/snowflake/securing-the-snowflake-storage-integration-on-aws-21046672f1a8?sk=8f5284f30824ec4210a0287f596ec3dd)  
- **"Building a Successful Data Initiative"** – *Towards Data Science, Oct 2020*

---

## **Education**

**University of Utah**  
Bachelor of Science, Mathematics (1996)

---

## **Technical Skills**

**Machine Learning & AI:** TensorFlow, PyTorch, Scikit-learn, XGBoost, MLFlow  
**Data Platforms:** Snowflake, Databricks, AWS Glue, dbt  
**Programming:** Python, SQL, Java, Node.js, R  
**Big Data & Pipelines:** Spark, Talend, EMR, RabbitMQ, Airflow  
**Visualization & BI:** Tableau, Jupyter, QlikView, Metabase  
**Cloud & DevOps:** AWS (S3, Lambda, Redshift), Kubernetes, GitOps, Flyway  
